---
tags: [FML, GDL]
title: 'Lecture 2: Part (1)'
created: '2021-09-20T11:50:00.258Z'
modified: '2021-09-20T12:08:26.749Z'
---

# Lecture 2: Part (1)

## Statistical Learning in a nutshell

Today I am going to talk about statistical learning, what is high-dimensional and what are the challenges that faces learning in high dimensional setting. This is the first part of the lecture 2 in Geometric Deep Learning which you can find it [here](https://www.youtube.com/watch?v=pNks-HVVPcI). 

So what's statistical learning? **Statistical learning theory** is a framework for machine learning drawing from the fields of statistics and functional analysis. Statistical learning theory deals with the problem of finding a predictive function based on data. Statistical learning theory has led to successful applications in fields such as computer vision, speech recognition, and bioinformatics [1]. A good definition, but probably you are still confused how it actually works, so in a nutshell **Statistical learning** has four components if you understand them, you know what is statistical learning, those components are:

- Data Distribution.
- Approximation Model.
- Error Metric.
- Estimation Algorithm

### Data Distribution


## References
[1] Trevor Hastie, Robert Tibshirani, Jerome Friedman (2009) The Elements of Statistical Learning, Springer-Verlag
